{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ART_KSAvgg16_(2).ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI5PeqkHILXg"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1UXIPvETrrAOv5-4wooxofXTgjO5-geeF\n",
        "\n",
        "#!gdown https://drive.google.com/drive/folders/1yTQHIhmlL3QSXX6VgAXBC85ndDLOEayT?usp\n",
        "\n",
        "#!gdown https://drive.google.com/uc?id=1yTQHIhmlL3QSXX6VgAXBC85ndDLOEayT\n",
        "\n",
        "#!gdown https://drive.google.com/uc?id=1yTQHIhmlL3QSXX6VgAXBC85ndDLOEayT\n",
        "#https://drive.google.com/drive/folders/1yTQHIhmlL3QSXX6VgAXBC85ndDLOEayT?usp=sharing\n",
        "#https://drive.google.com/drive/folders/1CtD7m0FD0BNcYAADjWHj_hlTHHUYTkTz?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW6JY7kg0SO7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWG0bN8SIPqs"
      },
      "source": [
        "!unzip T_S2.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npPEQJGqkDpu"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import AveragePooling2D #down sampling \n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G52nbIZkI2i"
      },
      "source": [
        "# initialize the initial learning rate, number of epochs to train for,\n",
        "# and batch size\n",
        "INIT_LR = 1e-3\n",
        "EPOCHS = 20\n",
        "BS = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWefNWrzjm9A"
      },
      "source": [
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images('/content/T_S2/Train'))\n",
        "data = []\n",
        "labels = []\n",
        "# loop over the image paths\n",
        "for imagePath in imagePaths:\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\t\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\timage = cv2.resize(image, (224, 224))\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)\n",
        "# convert the data and labels to NumPy arrays while scaling the pixel\n",
        "# intensities to the range [0, 1]\n",
        "data = np.array(data) / 255.0\n",
        "labels = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1P6SK38kT_C"
      },
      "source": [
        "# perform one-hot encoding on the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)\n",
        "# initialize the training data augmentation object\n",
        "trainAug = ImageDataGenerator(\n",
        "\trotation_range=15,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z02XZskykc7S"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmcQzi7qkm1u"
      },
      "source": [
        "# load the VGG16 network, ensuring the head FC layer sets are left\n",
        "# off\n",
        "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(64, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0wFa5oEk9Ca"
      },
      "source": [
        "# compile our model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainAug.flow(trainX, trainY, batch_size=BS),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tvalidation_steps=len(testX) // BS,\n",
        "\tepochs=EPOCHS)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv7lEaMTr87J"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "predY = model.predict(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5u36rE1tcmB"
      },
      "source": [
        "predY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5GClMBos5GS"
      },
      "source": [
        "labels = ['Makkah', 'Madena']\n",
        "cm = confusion_matrix(testY.argmax(axis=1),predY.argmax(axis=1))\n",
        "print(cm)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "plt.title('Confusion matrix of the classifier')\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + labels)\n",
        "ax.set_yticklabels([''] + labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.savefig('confusion_matrix.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgfFSW9Ep3Vl"
      },
      "source": [
        "# plot the training loss and accuracy\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on glaucoma Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"training&validation_accuracy.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzpCMfq5p7VU"
      },
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving ART_KSA model...\")\n",
        "model.save(\"ART_KSA.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMDFjkG1w6En"
      },
      "source": [
        "import shutil, random, os, cv2, random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI1lVQGx0vW9"
      },
      "source": [
        "from keras.preprocessing.image import img_to_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI0yCrcC0o2a"
      },
      "source": [
        "# load the image\n",
        "import shutil, random, os, cv2, random\n",
        "dirpath = \"//content/T_S2/Test\"\n",
        "type_ = random.sample(os.listdir(dirpath), 1)\n",
        "path = random.sample(os.listdir(os.path.join(dirpath,type_[0])), 1)\n",
        "#print(path)\n",
        "\n",
        "# load the image\n",
        "image = cv2.imread(os.path.join(dirpath,type_[0],path[0]))\n",
        "output =cv2.resize(image, (400, 400))\n",
        "# pre-process the image for classification\n",
        "image = cv2.resize(image, (224, 224))\n",
        "image = image.astype(\"float\") / 255.0\n",
        "image = img_to_array(image)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# classify the input image then find the indexes of the two class\n",
        "print(\"[INFO] classifying image...\")\n",
        "proba = model.predict(image)[0]\n",
        "idxs = np.argsort(proba)[::-1][:2]\n",
        "from google.colab.patches import cv2_imshow\n",
        "# loop over the indexes of the high confidence class labels\n",
        "label = \"Testing Image Type : {} \".format(type_[0])\n",
        "cv2.putText(output, label, (10, (1 * 20) + 25), \n",
        "  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (102, 178, 255), 2)\n",
        "  \n",
        "for (i, j) in enumerate(idxs):\n",
        "  label = \"{}: {:.2f}%\".format(lb.classes_[j], proba[j] * 100)\n",
        "  cv2.putText(output, label, (10, ((i+2) * 30) + 25), \n",
        "\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "# show the probabilities for each of the individual labels\n",
        "for (label, p) in zip(lb.classes_, proba):\n",
        "\tprint(\"{}: {:.2f}%\".format(label, p * 100))\n",
        "cv2_imshow(output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsNgiNBBcaMH"
      },
      "source": [
        "accuracies = cross_val_score(estimator = model , X=trainX , y=trainY, cv=4)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}